{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-k3_PtA_ZbSk","outputId":"3db17e4e-bbab-4fec-9e11-33cb2feaf174","executionInfo":{"status":"ok","timestamp":1754383398622,"user_tz":-480,"elapsed":110388,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai-whisper\n","  Downloading openai_whisper-20250625.tar.gz (803 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/803.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=6ae53edb8ed34dd1b3bba3309420c00208bdbbc8840401d77af735881dd3a838\n","  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\n","Successfully built openai-whisper\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n","Collecting whisperx\n","  Downloading whisperx-3.4.2-py3-none-any.whl.metadata (16 kB)\n","Collecting ctranslate2<4.5.0 (from whisperx)\n","  Downloading ctranslate2-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Collecting faster-whisper>=1.1.1 (from whisperx)\n","  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from whisperx) (3.9.1)\n","Requirement already satisfied: numpy>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from whisperx) (2.0.2)\n","Collecting onnxruntime>=1.19 (from whisperx)\n","  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Collecting pandas>=2.2.3 (from whisperx)\n","  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyannote-audio>=3.3.2 (from whisperx)\n","  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx) (2.6.0+cu124)\n","Requirement already satisfied: torchaudio>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx) (2.6.0+cu124)\n","Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.11/dist-packages (from whisperx) (4.54.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<4.5.0->whisperx) (75.2.0)\n","Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<4.5.0->whisperx) (6.0.2)\n","Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx) (0.34.1)\n","Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx) (0.21.2)\n","Collecting av>=11 (from faster-whisper>=1.1.1->whisperx)\n","  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx) (4.67.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx) (2024.11.6)\n","Collecting coloredlogs (from onnxruntime>=1.19->whisperx)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx) (25.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx) (1.13.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx) (2025.2)\n","Collecting asteroid-filterbanks>=0.4 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx) (0.8.1)\n","Collecting lightning>=2.0.1 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx) (2.3.0)\n","Collecting pyannote.core>=5.0.0 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n","Collecting pyannote.database>=5.0.1 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pyannote.metrics>=3.2 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n","Collecting pyannote.pipeline>=3.0.1 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n","Collecting pytorch-metric-learning>=2.1.0 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx) (13.9.4)\n","Collecting semver>=3.0.0 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx) (0.13.1)\n","Collecting speechbrain>=1.0.0 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n","Collecting tensorboardX>=2.6 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n","Collecting torch-audiomentations>=0.11.0 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n","Collecting torchmetrics>=0.11.0 (from pyannote-audio>=3.3.2->whisperx)\n","  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx) (3.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.19->whisperx) (1.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx) (0.5.3)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper>=1.1.1->whisperx) (1.1.5)\n","Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx)\n","  Downloading lightning_utilities-0.15.1-py3-none-any.whl.metadata (5.7 kB)\n","Collecting pytorch-lightning (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx)\n","  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote-audio>=3.3.2->whisperx) (4.9.3)\n","Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx) (2.4.0)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx) (1.16.0)\n","Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx) (0.16.0)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (1.6.1)\n","Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (0.9.0)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (3.10.0)\n","Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx)\n","  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->whisperx) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx) (2.19.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx) (1.17.1)\n","Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx)\n","  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx) (0.2.0)\n","Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx)\n","  Downloading julius-0.2.7.tar.gz (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx)\n","  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.19->whisperx)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->whisperx) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx) (2025.7.14)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx) (2.22)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (3.12.14)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio>=3.3.2->whisperx) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (3.2.3)\n","Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx)\n","  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (2.0.41)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (3.6.0)\n","Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx)\n","  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx) (1.5.4)\n","Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx)\n","  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (1.20.1)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (1.1.3)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx)\n","  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (3.2.3)\n","Downloading whisperx-3.4.2-py3-none-any.whl (16.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ctranslate2-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n","Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning-2.5.2-py3-none-any.whl (821 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n","Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n","Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.1-py3-none-any.whl (29 kB)\n","Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n","Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n","Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n","Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: docopt, julius\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f90db0c9526eb25be785c61b151285eee320c81e6d8148a879fd565affe50224\n","  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n","  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=35d76f1f1a6a5a5ff0f18d1a5a57900d3563ba9442c5e02d393d1726cd3a3e42\n","  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n","Successfully built docopt julius\n","Installing collected packages: primePy, docopt, tensorboardX, semver, ruamel.yaml.clib, lightning-utilities, humanfriendly, ctranslate2, colorlog, av, ruamel.yaml, pyannote.core, pandas, coloredlogs, alembic, optuna, onnxruntime, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, faster-whisper, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote-audio, whisperx\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed alembic-1.16.4 asteroid-filterbanks-0.4.0 av-15.0.0 coloredlogs-15.0.1 colorlog-6.9.0 ctranslate2-4.4.0 docopt-0.6.2 faster-whisper-1.1.1 humanfriendly-10.0 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.2 lightning-utilities-0.15.1 onnxruntime-1.22.1 optuna-4.4.0 pandas-2.3.1 primePy-1.3 pyannote-audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.2 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.4 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.8.0 whisperx-3.4.2\n","Collecting TorchCRF\n","  Downloading TorchCRF-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from TorchCRF) (2.0.2)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from TorchCRF) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->TorchCRF) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->TorchCRF) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->TorchCRF) (3.0.2)\n","Downloading TorchCRF-1.1.0-py3-none-any.whl (5.2 kB)\n","Installing collected packages: TorchCRF\n","Successfully installed TorchCRF-1.1.0\n"]}],"source":["!pip install openai-whisper\n","!pip install whisperx\n","!pip install TorchCRF"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kMsT_OZZbSn","outputId":"45217cbb-67c8-4c29-f733-8e6f413f82be","executionInfo":{"status":"ok","timestamp":1754383420181,"user_tz":-480,"elapsed":21544,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 139M/139M [00:13<00:00, 10.9MiB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["Whisper(\n","  (encoder): AudioEncoder(\n","    (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n","    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n","    (blocks): ModuleList(\n","      (0-5): 6 x ResidualAttentionBlock(\n","        (attn): MultiHeadAttention(\n","          (query): Linear(in_features=512, out_features=512, bias=True)\n","          (key): Linear(in_features=512, out_features=512, bias=False)\n","          (value): Linear(in_features=512, out_features=512, bias=True)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (0): Linear(in_features=512, out_features=2048, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (ln_post): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (decoder): TextDecoder(\n","    (token_embedding): Embedding(51864, 512)\n","    (blocks): ModuleList(\n","      (0-5): 6 x ResidualAttentionBlock(\n","        (attn): MultiHeadAttention(\n","          (query): Linear(in_features=512, out_features=512, bias=True)\n","          (key): Linear(in_features=512, out_features=512, bias=False)\n","          (value): Linear(in_features=512, out_features=512, bias=True)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (cross_attn): MultiHeadAttention(\n","          (query): Linear(in_features=512, out_features=512, bias=True)\n","          (key): Linear(in_features=512, out_features=512, bias=False)\n","          (value): Linear(in_features=512, out_features=512, bias=True)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (0): Linear(in_features=512, out_features=2048, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  )\n",")"]},"metadata":{},"execution_count":2}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","import torchaudio\n","from whisper import load_model\n","import whisper\n","import numpy as np\n","import whisperx\n","\n","Encoder_DIM = 512\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","whisper_model = load_model(name='base.en', download_root='./').to(device)\n","whisper_model.eval()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"s97sozcbZbSo","executionInfo":{"status":"ok","timestamp":1754383420223,"user_tz":-480,"elapsed":13,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["fcount = 0\n","def build_truncation_labels(word_segments, num_frames, frame_stride=0.02):\n","    global fcount\n","    labels = np.zeros(num_frames, dtype=np.float32)\n","    end_time = 0\n","    start_time = 0\n","    for word in word_segments:\n","        start_time = word['start']\n","        end_time = word['end']\n","        token_end_frame = int(round(end_time / frame_stride))\n","        token_start_frame = int(round(start_time / frame_stride))\n","        alpha = 1 / (token_end_frame - token_start_frame + 1)\n","        labels[token_start_frame:token_end_frame+1] += alpha\n","\n","    return torch.tensor(labels, dtype=torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFgYsbebHtqm","outputId":"b440542b-06f7-4855-cadd-d0169076171e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/whisper/__init__.py\n"]}],"source":["print(whisper.__file__)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nOXI3BUmZbSp","executionInfo":{"status":"ok","timestamp":1754395662392,"user_tz":-480,"elapsed":12242166,"user":{"displayName":"史子琦","userId":"00274115476832317455"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c77246b4-aa03-4a45-ab3d-c2eb0954fe8f"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.95G/5.95G [03:36<00:00, 29.4MB/s]\n","Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n","100%|██████████| 360M/360M [00:01<00:00, 317MB/s]\n"]}],"source":["import random\n","dataset = torchaudio.datasets.LIBRISPEECH('./data', url=\"train-clean-100\", download=True)\n","align_model, metadata = whisperx.load_align_model(language_code='en', device=device)\n","labels = []\n","encoder_outs = []\n","count = 0\n","\n","for i in range(len(dataset)):\n","    if(count >= 150000):\n","      break\n","    waveform, sr, transcript, *_ = dataset[i]\n","    if sr != 16000:\n","        waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n","    res = {\n","            \"segments\": [{\n","                \"start\": 0,\n","                \"end\": waveform.shape[1] / sr,\n","                \"text\": transcript\n","            }]\n","        }\n","    result = whisperx.align(res[\"segments\"], align_model, metadata, waveform[0], device, return_char_alignments=False)\n","    word_segments = result[\"word_segments\"]\n","    label = build_truncation_labels(word_segments, 3000)\n","    length = waveform.shape[1] / 16000\n","    flag = 0\n","    k = -1\n","    for word in word_segments:\n","        k += 1\n","        if(k%5 != 0):\n","          continue\n","        chunk_len = 1 if random.random() < 0.2 else 2\n","        start = word['end']\n","        end = start + chunk_len\n","        chunk = waveform[:, int(start * 16000):int(end * 16000)]\n","        if end > length:\n","            flag = 1\n","        chunk_padded = whisper.pad_or_trim(chunk)\n","        mel = whisper.log_mel_spectrogram(chunk_padded).to(device)\n","        with torch.no_grad():\n","            encoder_out = whisper_model.encoder(mel)\n","        encoder_out = encoder_out.squeeze(0)[:100]\n","        token_start = int(round(start / 0.02))\n","        token_end = token_start + chunk_len * 50\n","        label_chunk = label[token_start:token_end]\n","        pad_label = torch.zeros(encoder_out.shape[0] - label_chunk.shape[0])\n","        label_chunk = torch.cat((label_chunk, pad_label))\n","        count += 1\n","        labels.append(label_chunk.cpu())\n","        encoder_outs.append(encoder_out.cpu())\n","        if flag == 1:\n","            break"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RPgDyfrUYrS5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754396298416,"user_tz":-480,"elapsed":636038,"user":{"displayName":"史子琦","userId":"00274115476832317455"}},"outputId":"67ce04d4-8f51-44f9-9ccf-905f0a0ec610"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 322M/322M [00:17<00:00, 19.8MB/s]\n"]}],"source":["dev_dataset = torchaudio.datasets.LIBRISPEECH('./data', url=\"dev-clean\", download=True)\n","align_model, metadata = whisperx.load_align_model(language_code='en', device=device)\n","dev_labels = []\n","dev_encoder_outs = []\n","count = 0\n","\n","for i in range(len(dev_dataset)):\n","    if(count >= 8000):\n","      break\n","    waveform, sr, transcript, *_ = dev_dataset[i]\n","    if sr != 16000:\n","        waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n","    res = {\n","            \"segments\": [{\n","                \"start\": 0,\n","                \"end\": waveform.shape[1] / sr,\n","                \"text\": transcript\n","            }]\n","        }\n","    result = whisperx.align(res[\"segments\"], align_model, metadata, waveform[0], device, return_char_alignments=False)\n","    word_segments = result[\"word_segments\"]\n","    label = build_truncation_labels(word_segments, 3000)\n","    length = waveform.shape[1] / 16000\n","    flag = 0\n","    k = -1\n","    for word in word_segments:\n","        k += 1\n","        if(k%5 != 0):\n","          continue\n","        chunk_len = 1 if random.random() < 0.2 else 2\n","        start = word['end']\n","        end = start + chunk_len\n","        chunk = waveform[:, int(start * 16000):int(end * 16000)]\n","        if end > length:\n","            flag = 1\n","        chunk_padded = whisper.pad_or_trim(chunk)\n","        mel = whisper.log_mel_spectrogram(chunk_padded).to(device)\n","        with torch.no_grad():\n","            encoder_out = whisper_model.encoder(mel)\n","        encoder_out = encoder_out.squeeze(0)[:100]\n","        token_start = int(round(start / 0.02))\n","        token_end = token_start + chunk_len * 50\n","        label_chunk = label[token_start:token_end]\n","        pad_label = torch.zeros(encoder_out.shape[0] - label_chunk.shape[0])\n","        label_chunk = torch.cat((label_chunk, pad_label))\n","        count += 1\n","        dev_labels.append(label_chunk.cpu())\n","        dev_encoder_outs.append(encoder_out.cpu())\n","        if flag == 1:\n","            break"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pUNndjR9-Iwg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754397017537,"user_tz":-480,"elapsed":719112,"user":{"displayName":"史子琦","userId":"00274115476832317455"}},"outputId":"f3483663-e6b6-4cf2-dafb-64f57265b7cd"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 331M/331M [00:10<00:00, 33.5MB/s]\n"]}],"source":["test_dataset = torchaudio.datasets.LIBRISPEECH('./data', url=\"test-clean\", download=True)\n","align_model, metadata = whisperx.load_align_model(language_code='en', device=device)\n","test_labels = []\n","test_encoder_outs = []\n","count = 0\n","\n","for i in range(len(test_dataset)):\n","    if(count >= 8000):\n","      break\n","    waveform, sr, transcript, *_ = test_dataset[i]\n","    if sr != 16000:\n","        waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n","    res = {\n","            \"segments\": [{\n","                \"start\": 0,\n","                \"end\": waveform.shape[1] / sr,\n","                \"text\": transcript\n","            }]\n","        }\n","    result = whisperx.align(res[\"segments\"], align_model, metadata, waveform[0], device, return_char_alignments=False)\n","    word_segments = result[\"word_segments\"]\n","    label = build_truncation_labels(word_segments, 3000)\n","    length = waveform.shape[1] / 16000\n","    flag = 0\n","    k = 0\n","    for word in word_segments:\n","        k += 1\n","        if(k%5 != 0):\n","          continue\n","        chunk_len = 1 if random.random() < 0.2 else 2\n","        start = word['end']\n","        end = start + chunk_len\n","        chunk = waveform[:, int(start * 16000):int(end * 16000)]\n","        if end > length:\n","            flag = 1\n","        chunk_padded = whisper.pad_or_trim(chunk)\n","        mel = whisper.log_mel_spectrogram(chunk_padded).to(device)\n","        with torch.no_grad():\n","            encoder_out = whisper_model.encoder(mel)\n","        encoder_out = encoder_out.squeeze(0)[:100]\n","        token_start = int(round(start / 0.02))\n","        token_end = token_start + chunk_len * 50\n","        label_chunk = label[token_start:token_end]\n","        pad_label = torch.zeros(encoder_out.shape[0] - label_chunk.shape[0])\n","        label_chunk = torch.cat((label_chunk, pad_label))\n","        count += 1\n","        test_labels.append(label_chunk.cpu())\n","        test_encoder_outs.append(encoder_out.cpu())\n","        if flag == 1:\n","            break"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"i7FtC8liZbSp","executionInfo":{"status":"ok","timestamp":1754397017558,"user_tz":-480,"elapsed":26,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["class LSTMDataset(Dataset):\n","    def __init__(self, encoder_outs, labels, frame_stride=0.02):\n","        self.encoder_outs = encoder_outs\n","        self.frame_stride = frame_stride\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # Get encoder output\n","        encoder_out = self.encoder_outs[idx]\n","        encoder_out = encoder_out.to(device)\n","        # Get label\n","        label = self.labels[idx]\n","        label = label.to(device)\n","        return encoder_out, label"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2a8kVIaoZbSp","executionInfo":{"status":"ok","timestamp":1754397017577,"user_tz":-480,"elapsed":9,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def collate_fn(batch):\n","    encs, labs = zip(*batch)\n","    encs = torch.stack(encs)  # [B, T, D]\n","    labs = torch.stack(labs)  # [B, T]\n","    return encs, labs"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"U38nber5ZbSq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754397017602,"user_tz":-480,"elapsed":23,"user":{"displayName":"史子琦","userId":"00274115476832317455"}},"outputId":"99092f1c-ef9d-4fc5-e5d9-1fcc6d0a9b3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_size: 150001, dev_size: 8001, test_size: 8004\n"]}],"source":["train_dataset = LSTMDataset(encoder_outs, labels)\n","dev_dataset = LSTMDataset(dev_encoder_outs, dev_labels)\n","test_dataset = LSTMDataset(test_encoder_outs, test_labels)\n","train_size = len(train_dataset)\n","dev_size = len(dev_dataset)\n","test_size = len(test_dataset)\n","print(f\"train_size: {train_size}, dev_size: {dev_size}, test_size: {test_size}\")\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n","dev_dataloader = DataLoader(dev_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"WQTO5mFdBT8S","executionInfo":{"status":"ok","timestamp":1754397017615,"user_tz":-480,"elapsed":12,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["class LSTMTruncationDetector(nn.Module):\n","    def __init__(self, input_dim, hidden_dim=512, num_layers=2, bidirectional=True, dropout=0.3):\n","        super().__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n","                            batch_first=True, bidirectional=bidirectional, dropout=dropout)\n","        self.out_proj = nn.Linear(hidden_dim * (2 if bidirectional else 1), 1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):  # x: [B, T, D]\n","        lstm_out, _ = self.lstm(x)          # [B, T, H]\n","        lstm_out = self.dropout(lstm_out)\n","        logits = self.out_proj(lstm_out)    # [B, T, 1]\n","        alphas = torch.sigmoid(logits).squeeze(-1)  # [B, T]\n","        return alphas"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"iLen6zuVOZg2","executionInfo":{"status":"ok","timestamp":1754397017641,"user_tz":-480,"elapsed":24,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CIFTimeLoss(nn.Module):\n","    def __init__(self, lambda_time: float = 1.0, lambda_count: float = 1.0, lambda_blank: float = 1.0, eps: float = 1e-6):\n","        super().__init__()\n","        self.lambda_time = lambda_time\n","        self.lambda_count = lambda_count\n","        self.lambda_blank = lambda_blank\n","        self.eps = eps\n","        self.frame_reg_loss = nn.SmoothL1Loss(reduction='mean', beta=3.0)\n","        self.count_loss_fn = nn.SmoothL1Loss(reduction='mean', beta=0.1)\n","\n","    def forward(self, alpha: torch.Tensor, true_counts: torch.Tensor, true_frames_list: list, labs: torch.Tensor, epoch: int):\n","        device = alpha.device\n","        B, T = alpha.shape\n","\n","        sum_alpha = alpha.sum(dim=1)\n","        l_count = self.count_loss_fn(sum_alpha, true_counts)\n","\n","        A = torch.cumsum(alpha, dim=1)\n","\n","        l_time_sum = torch.tensor(0.0, device=device)\n","        valid_samples = 0\n","        beta = 2.0 + epoch * 0.5\n","        #ta = 1 / epoch\n","\n","        blank_mask = (labs == 0).float()\n","        l_blank = (alpha * blank_mask).sum() # sum or mean\n","\n","        for i in range(B):\n","            U_i = int(true_counts[i].item())\n","            if U_i <= 0:\n","                continue\n","\n","            A_i = A[i]\n","            thresholds = torch.arange(1, U_i+1, device=device, dtype=A_i.dtype)\n","\n","            diff = (A_i.unsqueeze(0) - thresholds.unsqueeze(1)).abs()\n","            penalty = (A_i.unsqueeze(0) - thresholds.unsqueeze(1)).clamp(min=0)\n","            # f = diff + 15 * penalty\n","            #weights = F.gumbel_softmax(diff, tau=ta, hard=True)\n","            weights = F.softmax(-beta * diff - 20 * penalty, dim=1)\n","\n","            t_idx = torch.arange(T, device=device, dtype=torch.float32)\n","            pred_frames = (weights * t_idx).sum(dim=1)\n","\n","            true_frames = true_frames_list[i].to(device).float()\n","            l_time_i = self.frame_reg_loss(pred_frames, true_frames)\n","\n","            l_time_sum += l_time_i\n","            valid_samples += 1\n","\n","        l_time = (l_time_sum / valid_samples) if valid_samples>0 else torch.tensor(0.0, device=device)\n","        loss   = self.lambda_count * l_count + self.lambda_time * l_time + self.lambda_blank * l_blank\n","        return loss, l_count, l_time, l_blank"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"nX6H9RdzZbSr","executionInfo":{"status":"ok","timestamp":1754397017754,"user_tz":-480,"elapsed":111,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["model = LSTMTruncationDetector(input_dim=Encoder_DIM).to(device)\n","criterion = CIFTimeLoss(lambda_count=2.0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"OiVKmosN69en","executionInfo":{"status":"ok","timestamp":1754397017759,"user_tz":-480,"elapsed":2,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def get_frame_lists(lab):\n","    cumsum = lab.cumsum(dim=0)\n","    total_tokens = int(lab.sum().item())\n","    fire_indices = []\n","    a = 1e-4\n","    for k in range(1, total_tokens + 1):\n","        idx = torch.searchsorted(cumsum, torch.tensor(k-a, device=cumsum.device)).item()\n","        fire_indices.append(idx)\n","    return torch.tensor(fire_indices, dtype=torch.long)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"mONEM8aiDGu5","executionInfo":{"status":"ok","timestamp":1754397017952,"user_tz":-480,"elapsed":177,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["least_dev_loss = 1e9"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"YwCoYu9eC3cu","colab":{"base_uri":"https://localhost:8080/","height":738},"executionInfo":{"status":"error","timestamp":1754405270080,"user_tz":-480,"elapsed":8252126,"user":{"displayName":"史子琦","userId":"00274115476832317455"}},"outputId":"2e63607b-b464-4ccc-dc2d-88e239e2fc3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Loss: 17.7949, Avg Diff: 0.3481, Dev Loss: 5.0657\n","  Count Loss: 0.3035, Frame Loss: 4.0894, Blank Loss: 0.3692\n","Model saved!\n","Epoch 2/20, Loss: 4.5585, Avg Diff: 0.3061, Dev Loss: 4.4485\n","  Count Loss: 0.2626, Frame Loss: 3.3451, Blank Loss: 0.5782\n","Model saved!\n","Epoch 3/20, Loss: 4.0870, Avg Diff: 0.3029, Dev Loss: 3.8291\n","  Count Loss: 0.2593, Frame Loss: 2.9411, Blank Loss: 0.3696\n","Model saved!\n","Epoch 4/20, Loss: 3.6911, Avg Diff: 0.2926, Dev Loss: 3.5032\n","  Count Loss: 0.2490, Frame Loss: 2.6726, Blank Loss: 0.3326\n","Model saved!\n","Epoch 5/20, Loss: 3.5296, Avg Diff: 0.3053, Dev Loss: 3.6057\n","  Count Loss: 0.2613, Frame Loss: 2.8565, Blank Loss: 0.2267\n","Epoch 6/20, Loss: 3.6987, Avg Diff: 0.2950, Dev Loss: 3.5349\n","  Count Loss: 0.2514, Frame Loss: 2.5099, Blank Loss: 0.5221\n","Epoch 7/20, Loss: 3.3627, Avg Diff: 0.2927, Dev Loss: 3.5703\n","  Count Loss: 0.2499, Frame Loss: 2.5984, Blank Loss: 0.4720\n","Epoch 8/20, Loss: 3.3213, Avg Diff: 0.2996, Dev Loss: 3.5351\n","  Count Loss: 0.2564, Frame Loss: 2.6808, Blank Loss: 0.3415\n","Epoch 9/20, Loss: 3.9711, Avg Diff: 0.3111, Dev Loss: 4.1049\n","  Count Loss: 0.2678, Frame Loss: 2.8380, Blank Loss: 0.7313\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4157797003.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtrue_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrue_frames_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_frame_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4283258828.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# x: [B, T, D]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# [B, T, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# [B, T, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","num_epochs = 20\n","for epoch in range(1, num_epochs + 1):\n","    model.train()\n","    epoch_loss = 0.0\n","    dev_loss = 0.0\n","    dev_loss_count = 0.0\n","    dev_loss_frame = 0.0\n","    dev_loss_blank = 0.0\n","    all_diffs = []\n","\n","    for enc, lab in train_dataloader:\n","        batch_size, seq_len, _ = enc.size()\n","        alphas = model(enc)\n","        true_counts = lab.sum(dim=-1).float()\n","        true_frames_list = [get_frame_lists(lab[i]) for i in range(batch_size)]\n","        loss, _, _, _ = criterion(alphas, true_counts, true_frames_list, lab, epoch)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    model.eval()\n","    for enc, lab in test_dataloader:\n","        with torch.no_grad():\n","            batch_size, seq_len, _ = enc.size()\n","            alphas = model(enc)\n","            true_counts = lab.sum(dim=-1).float()\n","            true_frames_list = [get_frame_lists(lab[i]) for i in range(batch_size)]\n","            pred_counts = alphas.sum(dim=-1).float()\n","            diff = (pred_counts - true_counts).abs().cpu().numpy().tolist()\n","            loss, loss_count, loss_frame, loss_blank = criterion(alphas, true_counts, true_frames_list, lab, epoch)\n","            dev_loss += loss.item()\n","            dev_loss_count += loss_count.item()\n","            dev_loss_frame += loss_frame.item()\n","            dev_loss_blank += loss_blank.item()\n","            all_diffs.extend(diff)\n","    epoch_loss /= len(train_dataloader)\n","    dev_loss /= len(test_dataloader)\n","    dev_loss_count /= len(test_dataloader)\n","    dev_loss_frame /= len(test_dataloader)\n","    dev_loss_blank /= len(test_dataloader)\n","    avg_diff = np.mean(all_diffs)\n","    print(f\"Epoch {epoch}/{num_epochs}, Loss: {epoch_loss:.4f}, Avg Diff: {avg_diff:.4f}, Dev Loss: {dev_loss:.4f}\")\n","    print(f\"  Count Loss: {dev_loss_count:.4f}, Frame Loss: {dev_loss_frame:.4f}, Blank Loss: {dev_loss_blank:.4f}\")\n","    if dev_loss < least_dev_loss:\n","        least_dev_loss = dev_loss\n","        torch.save(model.state_dict(), f\"model.pth\")\n","        print(\"Model saved!\")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"2nhHPppGTLiP","executionInfo":{"status":"ok","timestamp":1754405272563,"user_tz":-480,"elapsed":2,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def get_token_frame_intervals(alphas: torch.Tensor, threshold: float = 1.0):\n","    B, T = alphas.size()\n","    token_counts = []\n","    intervals = []\n","\n","    for b in range(B):\n","        integrate = 0.0\n","        prev_fire = -1\n","        samps = alphas[b].tolist()\n","\n","        this_intervals = []\n","        for t, a in enumerate(samps):\n","            integrate += a\n","            if integrate >= threshold:\n","                start = prev_fire + 1\n","                end   = t\n","                this_intervals.append((start, end))\n","                prev_fire = t\n","                integrate -= threshold\n","\n","        token_counts.append(len(this_intervals))\n","        intervals.append(this_intervals)\n","\n","    return token_counts, intervals"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"-AZEBb2Ln3YW","executionInfo":{"status":"ok","timestamp":1754405274064,"user_tz":-480,"elapsed":14,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def get_token_frame_intervals_single(alphas: torch.Tensor, threshold: float = 1.0):\n","    integrate = 0.0\n","    prev_fire = -1\n","    samps = alphas.tolist()\n","\n","    intervals = []\n","    for t, a in enumerate(samps):\n","        integrate += a\n","        if integrate >= threshold:\n","            start = prev_fire + 1\n","            end = t\n","            intervals.append((start, end))\n","            prev_fire = t\n","            integrate -= threshold\n","\n","    token_count = len(intervals)\n","    return token_count, intervals"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4B6J2nX7hoSA"},"outputs":[],"source":["# def resize(alphas: torch.Tensor,\n","#            target_lengths: torch.Tensor,\n","#            noise: float = 0.0,\n","#            threshold: float = 1.0,\n","#            max_iter: int = 20):\n","#     device = alphas.device\n","#     B, T = alphas.size()\n","\n","#     orig_sums = alphas.sum(dim=-1)\n","\n","#     num = float(target_lengths)\n","#     if noise > 0:\n","#         num = num + noise * torch.rand_like(num)\n","\n","#     scale = (num / (orig_sums + 1e-8)).unsqueeze(1)\n","#     resized = alphas * scale\n","\n","#     for _ in range(max_iter):\n","#         mask_exceed = resized > threshold\n","#         if not mask_exceed.any():\n","#             break\n","#         for b in torch.unique(mask_exceed.nonzero()[:,0]):\n","#             row = resized[b]\n","#             mask = row.ne(0).float()\n","#             mean_val = 0.5 * row.sum() / (mask.sum() + 1e-8)\n","#             resized[b] = row * 0.5 + mean_val * mask\n","\n","#     return resized, orig_sums"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"vIXK07LjmtrR","executionInfo":{"status":"ok","timestamp":1754405275649,"user_tz":-480,"elapsed":16,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def resize_single(alphas: torch.Tensor,\n","              target_length,\n","              noise: float = 0.0,\n","              threshold: float = 1.0,\n","              max_iter: int = 20):\n","\n","    device = alphas.device\n","    orig_sum = alphas.sum()\n","\n","    if isinstance(target_length, torch.Tensor):\n","        num = target_length.to(device)\n","    else:\n","        num = torch.tensor(float(target_length), device=device)\n","\n","    if noise > 0:\n","        num = num + noise * torch.rand((), device=device)\n","\n","    scale = num / (orig_sum + 1e-8)\n","    resized = alphas * scale\n","\n","    for _ in range(max_iter):\n","        mask_exceed = resized > threshold\n","        if not mask_exceed.any():\n","            break\n","\n","        row = resized\n","        mask = row.ne(0).float()\n","        mean_val = 0.5 * row.sum() / (mask.sum() + 1e-8)\n","        resized = row * 0.5 + mean_val * mask\n","\n","    return resized, orig_sum"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"FDPkbj1uHwZO","executionInfo":{"status":"ok","timestamp":1754405277082,"user_tz":-480,"elapsed":76,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def truncate_alphas(alphas: torch.Tensor, threshold: float = 1.0) -> torch.Tensor:\n","    B, T = alphas.shape\n","    device = alphas.device\n","\n","    truncated = alphas.clone()\n","\n","    for b in range(B):\n","        row = alphas[b]\n","        A = torch.cumsum(row, dim=0)\n","\n","        total = A[-1].item()\n","        K = torch.floor(torch.tensor(total / threshold, device=device)) * threshold\n","        if K < threshold:\n","            left = 0\n","            continue\n","        left = total - K\n","        idx = (A >= K).nonzero(as_tuple=False)\n","        t_last = idx[0, 0].item()\n","\n","        if t_last + 1 < T:\n","            truncated[b, t_last+1 :] = 0.0\n","\n","    return truncated, left"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"nTMKjZ6ChUdd","executionInfo":{"status":"ok","timestamp":1754405278222,"user_tz":-480,"elapsed":2,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def Judge_truncate(pred_interval, left, alpha):\n","    if len(pred_interval) == 0:\n","        return False, alpha\n","    last_interval = pred_interval[-1]\n","    if last_interval[1] == 49 and len(pred_interval) != 1:\n","        alpha[last_interval[0]:] = 0.0\n","        return True, alpha\n","    if last_interval[1] <= 45 and left >= 0.09:\n","        return True, alpha\n","    return False, alpha"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ev7ygKT7DGu7","executionInfo":{"status":"ok","timestamp":1754405279386,"user_tz":-480,"elapsed":21,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[],"source":["def train_frame(alpha, count):\n","    U_i = int(count)\n","    if U_i <= 0:\n","        return []\n","    A_i = torch.cumsum(alpha, dim=0)\n","    thresholds = torch.arange(1, U_i+1, device=device, dtype=A_i.dtype)\n","\n","    diff = (A_i.unsqueeze(0) - thresholds.unsqueeze(1)).abs()\n","    penalty = (A_i.unsqueeze(0) - thresholds.unsqueeze(1)).clamp(min=0)\n","    f = diff\n","    weights = F.softmax(-10 * f - 10 * penalty, dim=1)\n","\n","    t_idx = torch.arange(50, device=device, dtype=torch.float32)\n","    pred_frames = (weights * t_idx).sum(dim=1)\n","    return pred_frames"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeaR84awDGu7","outputId":"c0a9066d-a69e-4d5b-c9e1-1010c1a41464","executionInfo":{"status":"ok","timestamp":1754405280675,"user_tz":-480,"elapsed":11,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"source":["model.load_state_dict(torch.load(\"model.pth\"))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"ofKJ3KnRTLiP","outputId":"168e5580-4d7d-4f55-dfe0-95a9268322aa","executionInfo":{"status":"error","timestamp":1754405281518,"user_tz":-480,"elapsed":172,"user":{"displayName":"史子琦","userId":"00274115476832317455"}}},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (100) must match the size of tensor b (50) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4018669070.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtrue_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0ma_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mtrain_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mtrue_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frame_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpred_token_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token_frame_intervals_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3114352931.py\u001b[0m in \u001b[0;36mtrain_frame\u001b[0;34m(alpha, count)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpred_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpred_frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (50) at non-singleton dimension 1"]}],"source":["model.eval()\n","ct1 = 0\n","ct2 = 0\n","diffs = []\n","criterion = CIFTimeLoss()\n","for enc, lab in test_dataloader:\n","    with torch.no_grad():\n","        batch_size, seq_len, _ = enc.size()\n","        alphas = model(enc)\n","        true_counts = lab.sum(dim=-1).float()\n","        for b in range(enc.size(0)):\n","            true_count = true_counts[b]\n","            a_sum = alphas[b].sum()\n","            train_frames = train_frame(alphas[b], true_count)\n","            true_frames = get_frame_lists(lab[b])\n","            pred_token_count, pred_interval = get_token_frame_intervals_single(alphas[b], threshold=0.99)\n","            # if true_count != 1:\n","            #   continue\n","            print(f\"  true_counts: {true_counts[b]}, a_sum: {a_sum}\")\n","            print(f\"  train_frames: {train_frames}\")\n","            print(f\"  true_frames: {true_frames}\")\n","            print(f\"  pred_interval: {pred_interval}\")\n","            print(alphas[b][0:10])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9jxC_gNml8y"},"outputs":[],"source":["np.max(diffs)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"voice","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.21"}},"nbformat":4,"nbformat_minor":0}